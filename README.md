# Measuring encyclopedic and grammatical content in silent gesture

Precis:
  - Q1: Can participants with no sign language experience detect whether silent gestures represent transitive or intransitive events? See "/gesture-transitivity-project"
  - Q2: How accurate are non-signing participants at guessing the encyclopedic content of silent gestures? See "/gesture-meaning-project"
  - Conducted (1) live action vignette and (2) silent-gesture labeling experiments; 20-30 sentences collected for 69 live action events depicted by 6 hearing non-signers (=414 silent gestures) 
  - Initial analysis suggests:
    - transitivity is transparent: non-signers are accurate at guessing the transitivity of silent gestures
    - non-signer transitivity judgments can be predicted by the visual characteristics of the silent gestures
    - the encyclopedic content of silent gesture is not as ambiguous as previously assumed
  
# Files
 - `data.csv`: Raw data file containing the title of the gesture video, the inherent transitivity of the gesture video ('1' = transitive), the subject code for the gesturer, the subject code for the AMT respondent, a sentence describing the gesture, the main verb of the sentence, and the transitivity of the sentence
 - `data_processed.csv`: Summary data, including the item, its mean transitivity score, SDI/H-index, handshape characteristics, etc.
 
# To do
- [ ] Uplouad .py file that generates `data_processed.csv`
- [ ] Upload main analysis scripts
